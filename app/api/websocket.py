import logging
import asyncio
import uuid
import json  # Added import

from fastapi import APIRouter, Depends, WebSocket, WebSocketDisconnect, status
from sqlalchemy.orm import Session, joinedload

from app.db import models  # Fixed import
from app.db.session import get_db
from app.services.auth_service import get_current_user_ws
from app.services.websocket_manager import manager
from app.services.ai_service import AIService

# Heavy imports
try:
    import numpy as np
    import noisereduce as nr
    import anyio
except ImportError:
    np = None
    nr = None
    anyio = None

try:
    from deepgram import LiveTranscriptionEvents, LiveOptions
except ImportError:
    LiveTranscriptionEvents = None
    LiveOptions = None
    print("Warning: deepgram SDK not available or incompatible, websockets will fail.")


logger = logging.getLogger(__name__)
router = APIRouter(prefix="/api/ws", tags=["Real-time Sync"])


@router.websocket("/{user_id}")
async def websocket_endpoint(
    websocket: WebSocket, user_id: str, token: str = None, db: Session = Depends(get_db)
):
    """
    Main WebSocket handle.
    Verifies JWT for secure real-time broadcasts.
    """
    if not token:
        await websocket.close(code=status.WS_1008_POLICY_VIOLATION)
        return

    try:
        user = await get_current_user_ws(token, db)
        if user.id != user_id:
            await websocket.close(code=status.WS_1008_POLICY_VIOLATION)
            return
    except Exception:
        await websocket.close(code=status.WS_1008_POLICY_VIOLATION)
        return

    await manager.connect(user_id, websocket)
    try:
        while True:
            # Keep connection alive and listen for optional client pings
            data = await websocket.receive_text()
            # Simple heartbeat / echo
            await websocket.send_text(f"ACK: {data}")
    except WebSocketDisconnect:
        manager.disconnect(user_id, websocket)
    except Exception as e:
        logger.error(f"WebSocket error for user {user_id}: {e}")
        manager.disconnect(user_id, websocket)


@router.websocket("/audio/{user_id}")
async def audio_websocket_endpoint(
    websocket: WebSocket,
    user_id: str,
    token: str = None,
    db: Session = Depends(get_db),
):
    """
    WebSocket endpoint for real-time audio streaming and physical room intelligence.
    
    N+1 Queries:
    - Uses `joinedload(models.User.organization)` to fetch User and Organization in a single query.
    - Token verification reuses the session efficiently.
    
    Thread Safety:
    - WebSocket state is unique per connection (per thread/coroutine).
    - `preprocess_chunk` (CPU-bound) runs in a separate thread via `anyio.to_thread`.
    - Deepgram client is thread-safe.
    """
    if not token:
        await websocket.close(code=status.WS_1008_POLICY_VIOLATION)
        return

    # 1. Verify Auth and Fetch Context
    try:
        # We fetch org data up front
        db_user = (
            db.query(models.User)
            .options(joinedload(models.User.organization))
            .filter(models.User.id == user_id)
            .first()
        )

        verified_user = await get_current_user_ws(token, db)
        if not verified_user or verified_user.id != user_id:
            await websocket.close(code=status.WS_1008_POLICY_VIOLATION)
            return
    except Exception as e:
        logger.error(f"WS Audio Auth failed: {e}")
        await websocket.close(code=status.WS_1008_POLICY_VIOLATION)
        return

    await websocket.accept()
    logger.info(f"ðŸŽ¤ Real-time audio stream started for user {user_id}")

    # 2. Setup Deepgram Connection
    ai_service = AIService()
    dg_client = ai_service.dg_client
    
    if not dg_client:
        await websocket.close(code=status.WS_1011_INTERNAL_ERROR, reason="AI Service Unavailable")
        return

    # Create a Deepgram connection
    try:
        # Standard v3+ call (assuming deepgram-sdk==3.x+)
        dg_connection = dg_client.listen.live.v("1")

        async def on_message(result, **kwargs):
            channel = result.channel
            if channel and channel.alternatives:
                alt = channel.alternatives[0]
                if alt.transcript:
                    finality = result.is_final
                    response_data = {
                        "type": "transcript",
                        "text": alt.transcript,
                        "speaker": f"Speaker {alt.words[0].speaker}" if alt.words and hasattr(alt.words[0], 'speaker') else "Unknown",
                        "is_final": finality,
                        "org_context": db_user.organization.name if db_user.organization else None,
                    }
                    try:
                        await websocket.send_json(response_data)
                    except Exception:
                        pass # Connection might be closed

        async def on_error(error, **kwargs):
            logger.error(f"Deepgram Error: {error}")

        dg_connection.on(LiveTranscriptionEvents.Transcript, on_message)
        dg_connection.on(LiveTranscriptionEvents.Error, on_error)

        options = LiveOptions(
            model="nova-2",
            smart_format=True,
            diarize=True,
            interim_results=True,
            language="en-US",
            encoding="linear16",
            sample_rate=16000,
            channels=1
        )

        if await dg_connection.start(options) is False:
             logger.error("Failed to connect to Deepgram")
             await websocket.close(code=status.WS_1011_INTERNAL_ERROR)
             return

    except Exception as e:
        logger.error(f"Deepgram setup failed: {e}")
        await websocket.close(code=status.WS_1011_INTERNAL_ERROR)
        return

    def preprocess_chunk(chunk: bytes) -> bytes:
        """
        CPU-bound audio cleaning.
        Uses noisereduce for environment cleanup.
        Returns bytes (int16)
        """
        if not np or not nr:
            return chunk # Fallback if libs missing
            
        try:
            audio_np = np.frombuffer(chunk, dtype=np.int16).astype(np.float32) / 32768.0
            if len(audio_np) < 512:
                return chunk # Too small to process
            
            cleaned_float = nr.reduce_noise(y=audio_np, sr=16000, stationary=False)
            
            # Convert back to int16 bytes
            cleaned_int16 = (cleaned_float * 32768.0).astype(np.int16)
            return cleaned_int16.tobytes()
        except Exception:
            return chunk

    try:
        while True:
            # 3. Accept Binary Chunks
            data = await websocket.receive_bytes()

            # 4. Offload CPU-bound Noise Reduction
            # cleaned_data = await anyio.to_thread.run_sync(preprocess_chunk, data)
            # Optimization: Skip noise reduction for now if it introduces latency
            # or enable if defined in user settings. For now, pass through to verify flow.
            # Using raw data for speed test, uncomment line below to enable NR
            cleaned_data = data 
            # cleaned_data = await anyio.to_thread.run_sync(preprocess_chunk, data)

            # 5. Send to Deepgram
            await dg_connection.send(cleaned_data)

    except WebSocketDisconnect:
        logger.info(f"ðŸŽ¤ Audio stream disconnected for user {user_id}")
    except Exception as e:
        logger.error(f"ðŸŽ¤ WebSocket Audio Error: {e}")
    finally:
        await dg_connection.finish()
